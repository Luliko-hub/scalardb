{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Scalar DB A library that makes non-ACID distributed databases/storages ACID-compliant. It not only supports strongly-consistent ACID transactions, but also scales linearly and achieves high availability when it is deployed with distributed databases/storages such as Cassandra. Docs Getting started Design document Javadoc Jepsen tests Sample applications by contributors/collaborators Q A application (From Indetail Engineering team) Contributing This library is mainly maintained by the Scalar Engineering Team, but of course we appreciate any help. For asking questions, finding answers and helping other users, please go to scalardb-user (English only) or scalardb-user-ja (Japanese only) . For filing bugs, suggesting improvements, or requesting new features, help us out by opening an issue. License Scalar DB is dual-licensed under both the Apache 2.0 License (found in the LICENSE file in the root directory) and a commercial license. You may select, at your option, one of the above-listed licenses. The commercial license includes enterprise-grade tools, such as a multi-table consistent backup/restore tool for Cassandra. Regarding the commercial license, please contact us for more information.","title":"Home"},{"location":"#scalar-db","text":"A library that makes non-ACID distributed databases/storages ACID-compliant. It not only supports strongly-consistent ACID transactions, but also scales linearly and achieves high availability when it is deployed with distributed databases/storages such as Cassandra.","title":"Scalar DB"},{"location":"#docs","text":"Getting started Design document Javadoc Jepsen tests Sample applications by contributors/collaborators Q A application (From Indetail Engineering team)","title":"Docs"},{"location":"#contributing","text":"This library is mainly maintained by the Scalar Engineering Team, but of course we appreciate any help. For asking questions, finding answers and helping other users, please go to scalardb-user (English only) or scalardb-user-ja (Japanese only) . For filing bugs, suggesting improvements, or requesting new features, help us out by opening an issue.","title":"Contributing"},{"location":"#license","text":"Scalar DB is dual-licensed under both the Apache 2.0 License (found in the LICENSE file in the root directory) and a commercial license. You may select, at your option, one of the above-listed licenses. The commercial license includes enterprise-grade tools, such as a multi-table consistent backup/restore tool for Cassandra. Regarding the commercial license, please contact us for more information.","title":"License"},{"location":"design/","text":"Scalar DB v1 design document Introduction Scalar DB v1 is a distributed storage abstraction and client-coordinated distributed transaction manager on top of the storage. This design document briefly explains its background, design and implementation. Background and Objectives Distributed storage is widely adopted in real-world applications and recent open-source distributed storages such as Cassandra and HBase have accelerated the trend. They are particularly used by large and sometimes mission-critical applications because of their high performance, high availability and high scalability. However, they often lack transaction capability, which is particularly important in mission-critical applications. Transaction capability can be added to HBase via third-party libraries, but they tend to sacrifice some availability property due to the master-slave architecture. Some companies have ended up creating yet another distributed transactional databases from scratch (such as CockroachDB and TiDB) to overcome such problem. Scalar DB v1 is a simple and practical solution to solve the above mentioned problem in a different way. It provides a simple storage abstraction layer on the existing storage implementations and a storage-independent scalable distributed transaction layer on top of the storage abstraction. So, it can fully utilize, not only battle-tested existing implementations, operational/management tools and good properties of storages, but also the eco-system, the best practices and the community which have grown for a long time. Design Goals The primary design goals of Scalar DB are high availability, horizontal scalability and strong consistency for distributed storage and transaction operations. It aims to tolerate disk, machine, rack, and even data-center failures, with minimal performance degradation. It achieves these goals with an unbundled transaction layer [1] with easy and unified API so that the underlining storage implementations can be replaced with others without application code change. The performance of the Scalar DB is highly dependent on the underlying storage performance, and is usually slower than other scratch-built distributed databases since it adds a storage abstraction layer and storage-oblivious transaction layer. High-level Architecture Scalar DB is composed of distributed storage abstraction layer and client-coordinated distributed transaction manager. Distributed storage abstraction has storage implementation specific adapters such as Cassandra adapter. Another storage implementation can be added by creating an adapter which follows the abstraction interface. Data Model The data model of Scalar DB is a multi-dimensional map based on the key-value data model. A logical record is composed of partition-key, clustering-key and a set of values. The value is uniquely mapped by a primary key composed of partition-key, clustering-key and value-name as described in the following scheme. (partition-key, clustering-key, value-name) - value-content Physical Data Model Scalar DB is a multi-dimensional map distributed to multiple nodes by key-based hash partitioning. Records are assumed to be hash-partitioned by partition-key (even though an underlining implementation may support range partitioning). Records with the same partition-key define a partition. A partition is clustered (sorted) by the clustering-key. It is similar to Google BigTable [2] but it differs in clustering-key structure and partitioning scheme. Limitation of the data model Since records in Scalar DB are assumed to be hash-partitioned, global range scan is not supported. Range scan is only supported for clustering-key access within the same partition. Implementation Storage As of writing this, Scalar DB supports only Cassandra storage as a storage implementation. More correctly, it supports Cassandra java-driver API. Thus Cassandra java-driver compatible storage systems, such as ScyllaDB and Azure Cosmos DB, can potentially also be used. The storage abstraction assumes the following features/properties, which most recent distributed storages have: Atomic CRUD operations (each single-record operation needs to be atomic) Sequential consistency support Atomic/Linearizable conditional mutation (Create/Update/Delete) Ability to include user-defined meta-data for each record Please see the javadoc for more details and usage. Transaction Scalar DB executes transactions in a fully client-coordinated way so that it can do master-less transactions, which achieves almost linear scalability and high availability (especially when it is integrated with master-less Cassandra). It basically follows the Cherry Garcia protocol propsed in [3]. More specifically, Scalar DB achieves scalable distributed transaction by utilizing atomic conditional mutation for managing transaction state and storing WAL (Write-Ahead-Logging) records in distributed fashion in each record by using meta-data ability. It also has some similarity to paxos-commit [4]. Please see the javadoc for more details and usage. Future Work Support Hbase for another storage implementation for more performance. Utilize deterministic nature of Scalar DL (ledger middleware used for storing ledger information with Scalar DB) to avoid heavy-weight global consensus for linearizability and serializability. References [1] D. B. Lomet, A. Fekete, G. Weikum, and M. J. Zwilling. Unbundling Transaction Services in the Cloud. In CIDR, Jan. 2009. [2] Fay Chang , Jeffrey Dean , Sanjay Ghemawat , Wilson C. Hsieh , Deborah A. Wallach , Mike Burrows , Tushar Chandra , Andrew Fikes , Robert E. Gruber, Bigtable: A Distributed Storage System for Structured Data, ACM Transactions on Computer Systems (TOCS), v.26 n.2, p.1-26, June 2008. [3] A. Dey, A. Fekete, U. R\u00f6hm, \"Scalable Distributed Transactions across Heterogeneous Stores\", IEEE 31th International Conference on Data Engineering (ICDE), 2015. [4] Jim Gray , Leslie Lamport, Consensus on transaction commit, ACM Transactions on Database Systems (TODS), v.31 n.1, p.133-160, March 2006.","title":"Design"},{"location":"design/#scalar-db-v1-design-document","text":"","title":"Scalar DB v1 design document"},{"location":"design/#introduction","text":"Scalar DB v1 is a distributed storage abstraction and client-coordinated distributed transaction manager on top of the storage. This design document briefly explains its background, design and implementation.","title":"Introduction"},{"location":"design/#background-and-objectives","text":"Distributed storage is widely adopted in real-world applications and recent open-source distributed storages such as Cassandra and HBase have accelerated the trend. They are particularly used by large and sometimes mission-critical applications because of their high performance, high availability and high scalability. However, they often lack transaction capability, which is particularly important in mission-critical applications. Transaction capability can be added to HBase via third-party libraries, but they tend to sacrifice some availability property due to the master-slave architecture. Some companies have ended up creating yet another distributed transactional databases from scratch (such as CockroachDB and TiDB) to overcome such problem. Scalar DB v1 is a simple and practical solution to solve the above mentioned problem in a different way. It provides a simple storage abstraction layer on the existing storage implementations and a storage-independent scalable distributed transaction layer on top of the storage abstraction. So, it can fully utilize, not only battle-tested existing implementations, operational/management tools and good properties of storages, but also the eco-system, the best practices and the community which have grown for a long time.","title":"Background and Objectives"},{"location":"design/#design-goals","text":"The primary design goals of Scalar DB are high availability, horizontal scalability and strong consistency for distributed storage and transaction operations. It aims to tolerate disk, machine, rack, and even data-center failures, with minimal performance degradation. It achieves these goals with an unbundled transaction layer [1] with easy and unified API so that the underlining storage implementations can be replaced with others without application code change. The performance of the Scalar DB is highly dependent on the underlying storage performance, and is usually slower than other scratch-built distributed databases since it adds a storage abstraction layer and storage-oblivious transaction layer.","title":"Design Goals"},{"location":"design/#high-level-architecture","text":"Scalar DB is composed of distributed storage abstraction layer and client-coordinated distributed transaction manager. Distributed storage abstraction has storage implementation specific adapters such as Cassandra adapter. Another storage implementation can be added by creating an adapter which follows the abstraction interface.","title":"High-level Architecture"},{"location":"design/#data-model","text":"The data model of Scalar DB is a multi-dimensional map based on the key-value data model. A logical record is composed of partition-key, clustering-key and a set of values. The value is uniquely mapped by a primary key composed of partition-key, clustering-key and value-name as described in the following scheme. (partition-key, clustering-key, value-name) - value-content","title":"Data Model"},{"location":"design/#physical-data-model","text":"Scalar DB is a multi-dimensional map distributed to multiple nodes by key-based hash partitioning. Records are assumed to be hash-partitioned by partition-key (even though an underlining implementation may support range partitioning). Records with the same partition-key define a partition. A partition is clustered (sorted) by the clustering-key. It is similar to Google BigTable [2] but it differs in clustering-key structure and partitioning scheme.","title":"Physical Data Model"},{"location":"design/#limitation-of-the-data-model","text":"Since records in Scalar DB are assumed to be hash-partitioned, global range scan is not supported. Range scan is only supported for clustering-key access within the same partition.","title":"Limitation of the data model"},{"location":"design/#implementation","text":"","title":"Implementation"},{"location":"design/#storage","text":"As of writing this, Scalar DB supports only Cassandra storage as a storage implementation. More correctly, it supports Cassandra java-driver API. Thus Cassandra java-driver compatible storage systems, such as ScyllaDB and Azure Cosmos DB, can potentially also be used. The storage abstraction assumes the following features/properties, which most recent distributed storages have: Atomic CRUD operations (each single-record operation needs to be atomic) Sequential consistency support Atomic/Linearizable conditional mutation (Create/Update/Delete) Ability to include user-defined meta-data for each record Please see the javadoc for more details and usage.","title":"Storage"},{"location":"design/#transaction","text":"Scalar DB executes transactions in a fully client-coordinated way so that it can do master-less transactions, which achieves almost linear scalability and high availability (especially when it is integrated with master-less Cassandra). It basically follows the Cherry Garcia protocol propsed in [3]. More specifically, Scalar DB achieves scalable distributed transaction by utilizing atomic conditional mutation for managing transaction state and storing WAL (Write-Ahead-Logging) records in distributed fashion in each record by using meta-data ability. It also has some similarity to paxos-commit [4]. Please see the javadoc for more details and usage.","title":"Transaction"},{"location":"design/#future-work","text":"Support Hbase for another storage implementation for more performance. Utilize deterministic nature of Scalar DL (ledger middleware used for storing ledger information with Scalar DB) to avoid heavy-weight global consensus for linearizability and serializability.","title":"Future Work"},{"location":"design/#references","text":"[1] D. B. Lomet, A. Fekete, G. Weikum, and M. J. Zwilling. Unbundling Transaction Services in the Cloud. In CIDR, Jan. 2009. [2] Fay Chang , Jeffrey Dean , Sanjay Ghemawat , Wilson C. Hsieh , Deborah A. Wallach , Mike Burrows , Tushar Chandra , Andrew Fikes , Robert E. Gruber, Bigtable: A Distributed Storage System for Structured Data, ACM Transactions on Computer Systems (TOCS), v.26 n.2, p.1-26, June 2008. [3] A. Dey, A. Fekete, U. R\u00f6hm, \"Scalable Distributed Transactions across Heterogeneous Stores\", IEEE 31th International Conference on Data Engineering (ICDE), 2015. [4] Jim Gray , Leslie Lamport, Consensus on transaction commit, ACM Transactions on Database Systems (TODS), v.31 n.1, p.133-160, March 2006.","title":"References"},{"location":"getting-started/","text":"Getting Started with Scalar DB v1 Overview Scalar DB v1 is a library that provides a distributed storage abstraction and client-coordinated distributed transaction on the storage. This document briefly explains how you can get started with Scalar DB with a simple electronic money application. Install prerequisites Scalar DB v1 is written in Java and uses Cassandra as an underlining storage implementation, so the following software is required to run it. Oracle JDK 8 (OpenJDK 8) or higher Casssandra 3.11.x (the current stable version as of writing) Take a look at this document for how to set up Cassandra. Change commitlog_sync from periodic to batch in cassandra.yaml not to lose data when quorum of replica nodes go down Other libraries used from the above are automatically installed through gradle In addition to the above, the following software is needed to use schema tools. make Golang From here, we assume Oracle JDK 8, Cassandra 3.11.x, make and Golang are properly installed in your local environment, and Cassandra is running in your localhost. Build For building Scalar DB, what you will need to do is as follows. $ SCALARDB_HOME=/path/to/scalardb $ cd $SCALARDB_HOME $ ./gradlew installDist $ sudo mkdir /var/log/scalar; sudo chmod 777 /var/log/scalar $ cd tools/schema $ make $ cd - Or you can download from maven central repository . For example in Gradle, you can add the following dependency to your build.gradle. dependencies { compile group: 'com.scalar-labs', name: 'scalardb', version: '1.0.0-rc1' } Let's move to the getting-started directory so that we can avoid too much copy-and-paste. $ cd docs/getting-started Set up database schema First of all, you need to define how the data will be organized (a.k.a database schema) in the application with Scalar DB database schema. Here is a database schema for the sample application. For the supported data types, please see this doc for more details. REPLICATION FACTOR 1; CREATE NAMESPACE emoney; CREATE TABLE emoney.account ( id TEXT PARTITIONKEY, balance INT, ); To load the schema file, please run the following command. $ $SCALARDB_HOME/tools/schema/loader emoney-storage.sdbql Store retrieve data with storage service ElectronicMoneyWithStorage.java is a simple electronic money application with storage service. (Be careful: it is simplified for ease of reading and far from practical and is certainly not production-ready.) public class ElectronicMoneyWithStorage extends ElectronicMoney { private final StorageService service; public ElectronicMoneyWithStorage() { Injector injector = Guice.createInjector(new StorageModule(new DatabaseConfig(props))); service = injector.getInstance(StorageService.class); service.with(NAMESPACE, TABLENAME); } @Override public void charge(String id, int amount) throws ExecutionException { // Retrieve the current balance for id Get get = new Get(new Key(new TextValue(ID, id))); Optional Result result = service.get(get); // Calculate the balance int balance = amount; if (result.isPresent()) { int current = ((IntValue) result.get().getValue(BALANCE).get()).get(); balance += current; } // Update the balance Put put = new Put(new Key(new TextValue(ID, id))).withValue(new IntValue(BALANCE, balance)); service.put(put); } @Override public void pay(String fromId, String toId, int amount) throws ExecutionException { // Retrieve the current balances for ids Get fromGet = new Get(new Key(new TextValue(ID, fromId))); Get toGet = new Get(new Key(new TextValue(ID, toId))); Optional Result fromResult = service.get(fromGet); Optional Result toResult = service.get(toGet); // Calculate the balances (it assumes that both accounts exist) int newFromBalance = ((IntValue) (fromResult.get().getValue(BALANCE).get())).get() - amount; int newToBalance = ((IntValue) (toResult.get().getValue(BALANCE).get())).get() + amount; if (newFromBalance 0) { throw new RuntimeException(fromId + doesn't have enough balance. ); } // Update the balances Put fromPut = new Put(new Key(new TextValue(ID, fromId))) .withValue(new IntValue(BALANCE, newFromBalance)); Put toPut = new Put(new Key(new TextValue(ID, toId))).withValue(new IntValue(BALANCE, newToBalance)); service.put(fromPut); service.put(toPut); } @Override public void close() { service.close(); } } Now we can run the application. $ ../../gradlew run --args= -mode storage -action charge -amount 1000 -to user1 $ ../../gradlew run --args= -mode storage -action charge -amount 0 -to merchant1 $ ../../gradlew run --args= -mode storage -action pay -amount 100 -to merchant1 -from user1 Store retrieve data with transaction service The previous application seems fine under ideal conditions, but it is problematic when some failure happens during its operation or when multiple operations occur at the same time because it is not transactional. For example, money transfer (pay) from A's balance to B's balance is not done atomically in the application, and there might be a case where only A's balance is decreased (and B's balance is not increased) if a failure happens right after the first put and some money will be lost. With the transaction capability of Scalar DB, we can make such operations to be executed with ACID properties. Before updating the code, we need to update the schema to make it transaction capable by adding TRANSACTION keyword in CREATE TABLE . REPLICATION FACTOR 1; CREATE NAMESPACE emoney; CREATE TRANSACTION TABLE emoney.account ( id TEXT PARTITIONKEY, balance INT, ); Before reapplying the schema, please drop the existing namespace first by issuing the following. (Sorry you need to issue implementation specific commands to do this.) $ cqlsh -e drop keyspace emoney $ $SCALARDB_HOME/tools/schema/loader emoney-transaction.sdbql Now we can update the code as follows to make it transactional. public class ElectronicMoneyWithTransaction extends ElectronicMoney { private final TransactionService service; public ElectronicMoneyWithTransaction() { Injector injector = Guice.createInjector(new TransactionModule(new DatabaseConfig(props))); service = injector.getInstance(TransactionService.class); service.with(NAMESPACE, TABLENAME); } @Override public void charge(String id, int amount) throws CrudException, CommitException, UnknownTransactionStatusException { // Start a transaction DistributedTransaction tx = service.start(); // Retrieve the current balance for id Get get = new Get(new Key(new TextValue(ID, id))); Optional Result result = tx.get(get); // Calculate the balance int balance = amount; if (result.isPresent()) { int current = ((IntValue) result.get().getValue(BALANCE).get()).get(); balance += current; } // Update the balance Put put = new Put(new Key(new TextValue(ID, id))).withValue(new IntValue(BALANCE, balance)); tx.put(put); // Commit the transaction (records are automatically recovered in case of failure) tx.commit(); } @Override public void pay(String fromId, String toId, int amount) throws CrudException, CommitException, UnknownTransactionStatusException { // Start a transaction DistributedTransaction tx = service.start(); // Retrieve the current balances for ids Get fromGet = new Get(new Key(new TextValue(ID, fromId))); Get toGet = new Get(new Key(new TextValue(ID, toId))); Optional Result fromResult = tx.get(fromGet); Optional Result toResult = tx.get(toGet); // Calculate the balances (it assumes that both accounts exist) int newFromBalance = ((IntValue) (fromResult.get().getValue(BALANCE).get())).get() - amount; int newToBalance = ((IntValue) (toResult.get().getValue(BALANCE).get())).get() + amount; if (newFromBalance 0) { throw new RuntimeException(fromId + doesn't have enough balance. ); } // Update the balances Put fromPut = new Put(new Key(new TextValue(ID, fromId))) .withValue(new IntValue(BALANCE, newFromBalance)); Put toPut = new Put(new Key(new TextValue(ID, toId))).withValue(new IntValue(BALANCE, newToBalance)); tx.put(fromPut); tx.put(toPut); // Commit the transaction (records are automatically recovered in case of failure) tx.commit(); } @Override public void close() { service.close(); } } As you can see, it's not very different from the code with StorageService . This code instead uses TransactionService and all the CRUD operations are done through the DistributedTransaction object returned from TransactionService.start() . Now let's run the application with transaction mode. $ ../../gradlew run --args= -mode transaction -action charge -amount 1000 -to user1 $ ../../gradlew run --args= -mode transaction -action charge -amount 0 -to merchant1 $ ../../gradlew run --args= -mode transaction -action pay -amount 100 -to merchant1 -from user1 Further documentation These are just simple examples of how Scalar DB is used. For more information, please take a look at the following documents. Design Document Javadoc Database schema in Scalar DB","title":"Getting started"},{"location":"getting-started/#getting-started-with-scalar-db-v1","text":"","title":"Getting Started with Scalar DB v1"},{"location":"getting-started/#overview","text":"Scalar DB v1 is a library that provides a distributed storage abstraction and client-coordinated distributed transaction on the storage. This document briefly explains how you can get started with Scalar DB with a simple electronic money application.","title":"Overview"},{"location":"getting-started/#install-prerequisites","text":"Scalar DB v1 is written in Java and uses Cassandra as an underlining storage implementation, so the following software is required to run it. Oracle JDK 8 (OpenJDK 8) or higher Casssandra 3.11.x (the current stable version as of writing) Take a look at this document for how to set up Cassandra. Change commitlog_sync from periodic to batch in cassandra.yaml not to lose data when quorum of replica nodes go down Other libraries used from the above are automatically installed through gradle In addition to the above, the following software is needed to use schema tools. make Golang From here, we assume Oracle JDK 8, Cassandra 3.11.x, make and Golang are properly installed in your local environment, and Cassandra is running in your localhost.","title":"Install prerequisites"},{"location":"getting-started/#build","text":"For building Scalar DB, what you will need to do is as follows. $ SCALARDB_HOME=/path/to/scalardb $ cd $SCALARDB_HOME $ ./gradlew installDist $ sudo mkdir /var/log/scalar; sudo chmod 777 /var/log/scalar $ cd tools/schema $ make $ cd - Or you can download from maven central repository . For example in Gradle, you can add the following dependency to your build.gradle. dependencies { compile group: 'com.scalar-labs', name: 'scalardb', version: '1.0.0-rc1' } Let's move to the getting-started directory so that we can avoid too much copy-and-paste. $ cd docs/getting-started","title":"Build"},{"location":"getting-started/#set-up-database-schema","text":"First of all, you need to define how the data will be organized (a.k.a database schema) in the application with Scalar DB database schema. Here is a database schema for the sample application. For the supported data types, please see this doc for more details. REPLICATION FACTOR 1; CREATE NAMESPACE emoney; CREATE TABLE emoney.account ( id TEXT PARTITIONKEY, balance INT, ); To load the schema file, please run the following command. $ $SCALARDB_HOME/tools/schema/loader emoney-storage.sdbql","title":"Set up database schema"},{"location":"getting-started/#store-retrieve-data-with-storage-service","text":"ElectronicMoneyWithStorage.java is a simple electronic money application with storage service. (Be careful: it is simplified for ease of reading and far from practical and is certainly not production-ready.) public class ElectronicMoneyWithStorage extends ElectronicMoney { private final StorageService service; public ElectronicMoneyWithStorage() { Injector injector = Guice.createInjector(new StorageModule(new DatabaseConfig(props))); service = injector.getInstance(StorageService.class); service.with(NAMESPACE, TABLENAME); } @Override public void charge(String id, int amount) throws ExecutionException { // Retrieve the current balance for id Get get = new Get(new Key(new TextValue(ID, id))); Optional Result result = service.get(get); // Calculate the balance int balance = amount; if (result.isPresent()) { int current = ((IntValue) result.get().getValue(BALANCE).get()).get(); balance += current; } // Update the balance Put put = new Put(new Key(new TextValue(ID, id))).withValue(new IntValue(BALANCE, balance)); service.put(put); } @Override public void pay(String fromId, String toId, int amount) throws ExecutionException { // Retrieve the current balances for ids Get fromGet = new Get(new Key(new TextValue(ID, fromId))); Get toGet = new Get(new Key(new TextValue(ID, toId))); Optional Result fromResult = service.get(fromGet); Optional Result toResult = service.get(toGet); // Calculate the balances (it assumes that both accounts exist) int newFromBalance = ((IntValue) (fromResult.get().getValue(BALANCE).get())).get() - amount; int newToBalance = ((IntValue) (toResult.get().getValue(BALANCE).get())).get() + amount; if (newFromBalance 0) { throw new RuntimeException(fromId + doesn't have enough balance. ); } // Update the balances Put fromPut = new Put(new Key(new TextValue(ID, fromId))) .withValue(new IntValue(BALANCE, newFromBalance)); Put toPut = new Put(new Key(new TextValue(ID, toId))).withValue(new IntValue(BALANCE, newToBalance)); service.put(fromPut); service.put(toPut); } @Override public void close() { service.close(); } } Now we can run the application. $ ../../gradlew run --args= -mode storage -action charge -amount 1000 -to user1 $ ../../gradlew run --args= -mode storage -action charge -amount 0 -to merchant1 $ ../../gradlew run --args= -mode storage -action pay -amount 100 -to merchant1 -from user1","title":"Store &amp; retrieve data with storage service"},{"location":"getting-started/#store-retrieve-data-with-transaction-service","text":"The previous application seems fine under ideal conditions, but it is problematic when some failure happens during its operation or when multiple operations occur at the same time because it is not transactional. For example, money transfer (pay) from A's balance to B's balance is not done atomically in the application, and there might be a case where only A's balance is decreased (and B's balance is not increased) if a failure happens right after the first put and some money will be lost. With the transaction capability of Scalar DB, we can make such operations to be executed with ACID properties. Before updating the code, we need to update the schema to make it transaction capable by adding TRANSACTION keyword in CREATE TABLE . REPLICATION FACTOR 1; CREATE NAMESPACE emoney; CREATE TRANSACTION TABLE emoney.account ( id TEXT PARTITIONKEY, balance INT, ); Before reapplying the schema, please drop the existing namespace first by issuing the following. (Sorry you need to issue implementation specific commands to do this.) $ cqlsh -e drop keyspace emoney $ $SCALARDB_HOME/tools/schema/loader emoney-transaction.sdbql Now we can update the code as follows to make it transactional. public class ElectronicMoneyWithTransaction extends ElectronicMoney { private final TransactionService service; public ElectronicMoneyWithTransaction() { Injector injector = Guice.createInjector(new TransactionModule(new DatabaseConfig(props))); service = injector.getInstance(TransactionService.class); service.with(NAMESPACE, TABLENAME); } @Override public void charge(String id, int amount) throws CrudException, CommitException, UnknownTransactionStatusException { // Start a transaction DistributedTransaction tx = service.start(); // Retrieve the current balance for id Get get = new Get(new Key(new TextValue(ID, id))); Optional Result result = tx.get(get); // Calculate the balance int balance = amount; if (result.isPresent()) { int current = ((IntValue) result.get().getValue(BALANCE).get()).get(); balance += current; } // Update the balance Put put = new Put(new Key(new TextValue(ID, id))).withValue(new IntValue(BALANCE, balance)); tx.put(put); // Commit the transaction (records are automatically recovered in case of failure) tx.commit(); } @Override public void pay(String fromId, String toId, int amount) throws CrudException, CommitException, UnknownTransactionStatusException { // Start a transaction DistributedTransaction tx = service.start(); // Retrieve the current balances for ids Get fromGet = new Get(new Key(new TextValue(ID, fromId))); Get toGet = new Get(new Key(new TextValue(ID, toId))); Optional Result fromResult = tx.get(fromGet); Optional Result toResult = tx.get(toGet); // Calculate the balances (it assumes that both accounts exist) int newFromBalance = ((IntValue) (fromResult.get().getValue(BALANCE).get())).get() - amount; int newToBalance = ((IntValue) (toResult.get().getValue(BALANCE).get())).get() + amount; if (newFromBalance 0) { throw new RuntimeException(fromId + doesn't have enough balance. ); } // Update the balances Put fromPut = new Put(new Key(new TextValue(ID, fromId))) .withValue(new IntValue(BALANCE, newFromBalance)); Put toPut = new Put(new Key(new TextValue(ID, toId))).withValue(new IntValue(BALANCE, newToBalance)); tx.put(fromPut); tx.put(toPut); // Commit the transaction (records are automatically recovered in case of failure) tx.commit(); } @Override public void close() { service.close(); } } As you can see, it's not very different from the code with StorageService . This code instead uses TransactionService and all the CRUD operations are done through the DistributedTransaction object returned from TransactionService.start() . Now let's run the application with transaction mode. $ ../../gradlew run --args= -mode transaction -action charge -amount 1000 -to user1 $ ../../gradlew run --args= -mode transaction -action charge -amount 0 -to merchant1 $ ../../gradlew run --args= -mode transaction -action pay -amount 100 -to merchant1 -from user1","title":"Store &amp; retrieve data with transaction service"},{"location":"getting-started/#further-documentation","text":"These are just simple examples of how Scalar DB is used. For more information, please take a look at the following documents. Design Document Javadoc Database schema in Scalar DB","title":"Further documentation"},{"location":"jepsen/","text":"Jepsen tests for Scalar DB This guide will teach you how to run Jepsen tests for Scalar DB. The current tests use Cassandra test tools in Jepsen . How to run tests Get Jepsen which has Cassandra tests $ git clone -b cassandra https://github.com/scalar-labs/jepsen.git Copy this directory to your Jepsen directory $ cp -r ${SCALAR_DB_HOME}/jepsen/scalardb ${JEPSEN}/ Start Jepsen with docker The script starts 5 nodes and a control node (jepsen-control) $ cd ${JEPSEN}/docker $ ./up.sh Login jepsen-control $ docker exec -it jepsen-control bash Install Cassandra test tool and Cassaforte (Clojure wrapper for Cassandra) # in jepsen-control # Cassandra test tool $ cd /jepsen/cassandra $ lein install # Cassaforte $ git clone -b driver-3.0-for-jepsen https://github.com/scalar-labs/cassaforte $ cd cassaforte $ lein install Or, you can add the following lines after RUN cd /jepsen/jepsen lein install to ${JEPSEN}/docker/control/Dockerfile RUN cd /root git clone -b driver-3.0-for-jepsen https://github.com/scalar-labs/cassaforte RUN cd /root/cassaforte lein install RUN cd /jepsen/cassandra lein install Run a test of Scalar DB # in jepsen-control $ cd /jepsen/scalardb $ lein run test --test transfer --nemesis crash --join decommission --time-limit 300 Use lein run test --help to see a list of the full options","title":"Jepsen"},{"location":"jepsen/#jepsen-tests-for-scalar-db","text":"This guide will teach you how to run Jepsen tests for Scalar DB. The current tests use Cassandra test tools in Jepsen .","title":"Jepsen tests for Scalar DB"},{"location":"jepsen/#how-to-run-tests","text":"Get Jepsen which has Cassandra tests $ git clone -b cassandra https://github.com/scalar-labs/jepsen.git Copy this directory to your Jepsen directory $ cp -r ${SCALAR_DB_HOME}/jepsen/scalardb ${JEPSEN}/ Start Jepsen with docker The script starts 5 nodes and a control node (jepsen-control) $ cd ${JEPSEN}/docker $ ./up.sh Login jepsen-control $ docker exec -it jepsen-control bash Install Cassandra test tool and Cassaforte (Clojure wrapper for Cassandra) # in jepsen-control # Cassandra test tool $ cd /jepsen/cassandra $ lein install # Cassaforte $ git clone -b driver-3.0-for-jepsen https://github.com/scalar-labs/cassaforte $ cd cassaforte $ lein install Or, you can add the following lines after RUN cd /jepsen/jepsen lein install to ${JEPSEN}/docker/control/Dockerfile RUN cd /root git clone -b driver-3.0-for-jepsen https://github.com/scalar-labs/cassaforte RUN cd /root/cassaforte lein install RUN cd /jepsen/cassandra lein install Run a test of Scalar DB # in jepsen-control $ cd /jepsen/scalardb $ lein run test --test transfer --nemesis crash --join decommission --time-limit 300 Use lein run test --help to see a list of the full options","title":"How to run tests"},{"location":"schema-loader/","text":"Scalar DB Schema Tools This document briefly explains tools used to generate and load database schemas for Scalar DB. Scalar DB schema generator and loader Scalar DB schema generator (tools/schema/generator) generates storage implementation specific schema definition and metadata definition for Scalar DB transaction as described here for a given Scalar DB database schema. Scalar DB schema loader (tools/schema/loader) uses the generator to get an implementation specific schema file and load it with a storage implemtation specific loader for a give Scalar DB database schema. With the above tools, you don't need to think about implementation specific schemas when modeling data for your applications. Scalar DB schema definition Scalar DB schema is an abstract schema to define applications data with Scalar DB. Here is a spec of the definition. REPLICATION FACTOR number ';' CREATE NAMESPACE namespace_name ';' create_table_statement ::= CREATE [TRANSACTION] TABLE namespace_name'.'table_name '(' column_definition ( ',' column_definition )* ');' column_definition ::= column_name data_type [key_definition] data_type ::= BIGINT | BLOB | BOOLEAN | DOUBLE | FLOAT | INT | TEXT key_definition ::= PARTITIONKEY | CLUSTERINGKEY REPLICATION is a global command for replication factor. All the namespaces defined in the same file will have the specified replication factor. CREATE NAMESPACE is a command to define namespaces. CREATE [TRANSACTION] TABLE is a command to define tables. The grammar for defining tables is as stated above. If you add TRANSACTION keyword, the table is treated as transaction capable, and addtional metadata and coordinator namespace are added. please see this for more information about the metadata and the coordinator. Install Build Before installing, please install and setup golang . Then, make will download the required packages and build generator and loader. $ cd /path/to/scalardb/tools/schema $ make Use After defining a schema, please run the command as follows. You don't need --database option as of writing since the only supported database is cassandra . $ ./loader --help $ ./loader your-schema-file You can also generate implementation schema file only. $ ./generator --help $ ./generator your-schema-file","title":"Schema loader"},{"location":"schema-loader/#scalar-db-schema-tools","text":"This document briefly explains tools used to generate and load database schemas for Scalar DB.","title":"Scalar DB Schema Tools"},{"location":"schema-loader/#scalar-db-schema-generator-and-loader","text":"Scalar DB schema generator (tools/schema/generator) generates storage implementation specific schema definition and metadata definition for Scalar DB transaction as described here for a given Scalar DB database schema. Scalar DB schema loader (tools/schema/loader) uses the generator to get an implementation specific schema file and load it with a storage implemtation specific loader for a give Scalar DB database schema. With the above tools, you don't need to think about implementation specific schemas when modeling data for your applications.","title":"Scalar DB schema generator and loader"},{"location":"schema-loader/#scalar-db-schema-definition","text":"Scalar DB schema is an abstract schema to define applications data with Scalar DB. Here is a spec of the definition. REPLICATION FACTOR number ';' CREATE NAMESPACE namespace_name ';' create_table_statement ::= CREATE [TRANSACTION] TABLE namespace_name'.'table_name '(' column_definition ( ',' column_definition )* ');' column_definition ::= column_name data_type [key_definition] data_type ::= BIGINT | BLOB | BOOLEAN | DOUBLE | FLOAT | INT | TEXT key_definition ::= PARTITIONKEY | CLUSTERINGKEY REPLICATION is a global command for replication factor. All the namespaces defined in the same file will have the specified replication factor. CREATE NAMESPACE is a command to define namespaces. CREATE [TRANSACTION] TABLE is a command to define tables. The grammar for defining tables is as stated above. If you add TRANSACTION keyword, the table is treated as transaction capable, and addtional metadata and coordinator namespace are added. please see this for more information about the metadata and the coordinator.","title":"Scalar DB schema definition"},{"location":"schema-loader/#install-build","text":"Before installing, please install and setup golang . Then, make will download the required packages and build generator and loader. $ cd /path/to/scalardb/tools/schema $ make","title":"Install &amp; Build"},{"location":"schema-loader/#use","text":"After defining a schema, please run the command as follows. You don't need --database option as of writing since the only supported database is cassandra . $ ./loader --help $ ./loader your-schema-file You can also generate implementation schema file only. $ ./generator --help $ ./generator your-schema-file","title":"Use"},{"location":"schema/","text":"Database schema in Scalar DB Scalar DB has its own data model and schema and is mapped to a implementation-specific data model and schema. Also, it stores internal metadata for managing transaction logs and statuses. This document briefly explains how the data model and schema is mapped between Scalar DB and other implementations, and what are the internal metadata. Scalar DB and Cassandra The data model in Scalar DB is quite similar to the data model in Cassandra, except that in Scalar DB it is more like a simple key-value data model and it does not support secondary indexes. The primary key in Scalar DB is composed of one or more partition keys and zero or more clustering keys. Similarly, the primary key in Cassandra is composed of one or more partition keys and zero or more clustering columns. Data types supported in Scalar DB are a little more restricted than in Cassandra. Here are the supported data types and their mapping to Cassandra data types. Scalar DB Cassandra BOOLEAN boolean INT int BIGINT bigint FLOAT float DOUBLE double TEXT text BLOB blob Internal metadata in Scalar DB Scalar DB executes transactions in a client-coordinated manner by storing and retrieving metadata stored along with the actual records. Thus, along with any required values by the application, additional values for the metadata need to be defined in the schema. Here is an example schema in Cassandra when it is used with Scalar DB transactions. CREATE TABLE example.table1 ( ; keys and values required by an application k1 TEXT, k2 INT, v1 INT ; metadata for transaction management tx_id TEXT, tx_prepared_at BIGINT, tx_committed_at BIGINT, tx_state INT, tx_version INT, before_v1 INT, before_tx_committed_at BIGINT, before_tx_id TEXT, before_tx_prepared_at BIGINT, before_tx_state INT, before_tx_version INT, PRIMARY KEY (k1, k2) ); Let's assume that k1 is a partition key, k2 is a clustering key and v1 is a value, and those are the values required by an application. In addition to those, Scalar DB requires metadata for managing transactions. The rule behind it is as follows. * add tx_id , tx_prepared_at , tx_committed_at , tx_state , tx_version as metadata for the current record * add before_ prefixed values for each existing value except for primary keys (partition keys and clustering keys) for managing before image Additionally, we need a state table for managing transaction states as follows. CREATE TABLE IF NOT EXISTS coordinator.state ( tx_id text, tx_state int, tx_created_at bigint, PRIMARY KEY (tx_id) ); Schema generator and loader It is a little hard for application developers to care for the schema mapping and metadata for transactions, so we offer tools for generating and loading schema without much knowledge about imlementation schema and Scalar DB internal metadata. Please see this for more details.","title":"Database schema"},{"location":"schema/#database-schema-in-scalar-db","text":"Scalar DB has its own data model and schema and is mapped to a implementation-specific data model and schema. Also, it stores internal metadata for managing transaction logs and statuses. This document briefly explains how the data model and schema is mapped between Scalar DB and other implementations, and what are the internal metadata.","title":"Database schema in Scalar DB"},{"location":"schema/#scalar-db-and-cassandra","text":"The data model in Scalar DB is quite similar to the data model in Cassandra, except that in Scalar DB it is more like a simple key-value data model and it does not support secondary indexes. The primary key in Scalar DB is composed of one or more partition keys and zero or more clustering keys. Similarly, the primary key in Cassandra is composed of one or more partition keys and zero or more clustering columns. Data types supported in Scalar DB are a little more restricted than in Cassandra. Here are the supported data types and their mapping to Cassandra data types. Scalar DB Cassandra BOOLEAN boolean INT int BIGINT bigint FLOAT float DOUBLE double TEXT text BLOB blob","title":"Scalar DB and Cassandra"},{"location":"schema/#internal-metadata-in-scalar-db","text":"Scalar DB executes transactions in a client-coordinated manner by storing and retrieving metadata stored along with the actual records. Thus, along with any required values by the application, additional values for the metadata need to be defined in the schema. Here is an example schema in Cassandra when it is used with Scalar DB transactions. CREATE TABLE example.table1 ( ; keys and values required by an application k1 TEXT, k2 INT, v1 INT ; metadata for transaction management tx_id TEXT, tx_prepared_at BIGINT, tx_committed_at BIGINT, tx_state INT, tx_version INT, before_v1 INT, before_tx_committed_at BIGINT, before_tx_id TEXT, before_tx_prepared_at BIGINT, before_tx_state INT, before_tx_version INT, PRIMARY KEY (k1, k2) ); Let's assume that k1 is a partition key, k2 is a clustering key and v1 is a value, and those are the values required by an application. In addition to those, Scalar DB requires metadata for managing transactions. The rule behind it is as follows. * add tx_id , tx_prepared_at , tx_committed_at , tx_state , tx_version as metadata for the current record * add before_ prefixed values for each existing value except for primary keys (partition keys and clustering keys) for managing before image Additionally, we need a state table for managing transaction states as follows. CREATE TABLE IF NOT EXISTS coordinator.state ( tx_id text, tx_state int, tx_created_at bigint, PRIMARY KEY (tx_id) );","title":"Internal metadata in Scalar DB"},{"location":"schema/#schema-generator-and-loader","text":"It is a little hard for application developers to care for the schema mapping and metadata for transactions, so we offer tools for generating and loading schema without much knowledge about imlementation schema and Scalar DB internal metadata. Please see this for more details.","title":"Schema generator and loader"}]}